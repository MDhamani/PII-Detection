{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3337dace",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-04-14T19:58:45.103718Z",
     "iopub.status.busy": "2025-04-14T19:58:45.103471Z",
     "iopub.status.idle": "2025-04-14T19:59:19.454061Z",
     "shell.execute_reply": "2025-04-14T19:59:19.453409Z"
    },
    "papermill": {
     "duration": 34.356034,
     "end_time": "2025-04-14T19:59:19.455789",
     "exception": false,
     "start_time": "2025-04-14T19:58:45.099755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-14 19:59:03.292693: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1744660743.532520      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1744660743.596926      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import json\n",
    "import argparse\n",
    "from itertools import chain\n",
    "from functools import partial\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import AutoTokenizer, Trainer, TrainingArguments\n",
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification\n",
    "from datasets import Dataset, features\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74a6819c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:59:19.465437Z",
     "iopub.status.busy": "2025-04-14T19:59:19.464871Z",
     "iopub.status.idle": "2025-04-14T19:59:19.473779Z",
     "shell.execute_reply": "2025-04-14T19:59:19.473116Z"
    },
    "papermill": {
     "duration": 0.016468,
     "end_time": "2025-04-14T19:59:19.475311",
     "exception": false,
     "start_time": "2025-04-14T19:59:19.458843",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed=42):\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac67e49c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:59:19.481918Z",
     "iopub.status.busy": "2025-04-14T19:59:19.481680Z",
     "iopub.status.idle": "2025-04-14T19:59:19.485878Z",
     "shell.execute_reply": "2025-04-14T19:59:19.485110Z"
    },
    "papermill": {
     "duration": 0.008824,
     "end_time": "2025-04-14T19:59:19.487055",
     "exception": false,
     "start_time": "2025-04-14T19:59:19.478231",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "models = [\n",
    "    \"google-bert/bert-base-uncased\",\n",
    "    \"microsoft/deberta-v3-base\",\n",
    "]\n",
    "\n",
    "lr = [2e-5, 1e-5, 2e-3]\n",
    "sl = [768, 1024]\n",
    "frac = [0.6, 1]\n",
    "bs = [4, 8]\n",
    "dataset = [1, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e018f389",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:59:19.493167Z",
     "iopub.status.busy": "2025-04-14T19:59:19.492598Z",
     "iopub.status.idle": "2025-04-14T19:59:19.499216Z",
     "shell.execute_reply": "2025-04-14T19:59:19.498541Z"
    },
    "papermill": {
     "duration": 0.011063,
     "end_time": "2025-04-14T19:59:19.500478",
     "exception": false,
     "start_time": "2025-04-14T19:59:19.489415",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ConfigCreator:\n",
    "    def __init__(self, model_name=models[1], lr = lr[0], sl = sl[0], frac = frac[0], bs = bs[0], dataset = dataset[0]):\n",
    "        self.model_name = model_name\n",
    "        self.lr = lr\n",
    "        self.sl = sl\n",
    "        self.frac = frac\n",
    "        self.bs = bs\n",
    "        self.dataset = dataset\n",
    "    \n",
    "    def get_config(self):\n",
    "        class Config:\n",
    "            MODEL_NAME = self.model_name\n",
    "            MAX_SEQ_LEN = self.sl\n",
    "        \n",
    "            MODEL_SAVE_PATH = f\"/kaggle/working/{self.model_name.split('/')[1]}\"\n",
    "            SEED = 42\n",
    "            FRAC = self.frac\n",
    "            \n",
    "            NUM_FOLDS = 3\n",
    "        \n",
    "            DATASETS = {\n",
    "                0: \"/kaggle/input/pii-detection-removal-from-educational-data/train.json\",\n",
    "                1: \"/kaggle/input/pii-dd-mistral-generated/mixtral-8x7b-v1.json\",\n",
    "            }\n",
    "            USE_DATASETS = range(self.dataset)\n",
    "            \n",
    "            TOKENIZER = AutoTokenizer.from_pretrained(f\"/kaggle/input/pii-detection-v1/{self.model_name.split('/')[1]}_fold_0\")\n",
    "            LR = self.lr\n",
    "            WARMUP = 1e-1\n",
    "            WD = 1e-2\n",
    "            BS = self.bs\n",
    "            LOG = 10\n",
    "            ACC_STEPS = 2\n",
    "            EPOCHS = 3\n",
    "        \n",
    "        return Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c58c2c39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:59:19.506175Z",
     "iopub.status.busy": "2025-04-14T19:59:19.505907Z",
     "iopub.status.idle": "2025-04-14T19:59:19.525723Z",
     "shell.execute_reply": "2025-04-14T19:59:19.525123Z"
    },
    "papermill": {
     "duration": 0.024083,
     "end_time": "2025-04-14T19:59:19.526820",
     "exception": false,
     "start_time": "2025-04-14T19:59:19.502737",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Preprocessor():\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.data_paths = [self.config.DATASETS[i] for i in self.config.USE_DATASETS]\n",
    "\n",
    "    def __build_text_and_labels(self, example, target):\n",
    "        \"\"\"\n",
    "        Rebuild the text and align the labels based on tokens, provided labels, and whitespace information.\n",
    "    \n",
    "        Args:\n",
    "            example (dict): The input example containing tokens, labels, and whitespace information.\n",
    "    \n",
    "        Returns:\n",
    "            tuple: A tuple (text, aligned_labels), where text is the rebuilt text and aligned_labels is the list of corresponding labels.\n",
    "        \"\"\"\n",
    "        text = []\n",
    "        aligned_labels = []\n",
    "        targets = []\n",
    "\n",
    "        for token, label, has_whitespace in zip(example[\"tokens\"], example[\"given_labels\"], example[\"trailing_whitespace\"]):\n",
    "            text.append(token)\n",
    "            aligned_labels.extend([label] * len(token))\n",
    "    \n",
    "            if label in target:\n",
    "                targets.append(1)\n",
    "            else:\n",
    "                targets.append(0)\n",
    "    \n",
    "            if has_whitespace:\n",
    "                text.append(\" \")\n",
    "                aligned_labels.append(\"O\")\n",
    "    \n",
    "        return \"\".join(text), np.array(aligned_labels), targets\n",
    "\n",
    "    def __tokenize_text(self, text, max_seq_len, truncation=True):\n",
    "        \"\"\"\n",
    "        Tokenize the full text using the tokenizer and return tokenized output.\n",
    "    \n",
    "        Args:\n",
    "            text (str): The text to tokenize.\n",
    "            tokenizer (object): The tokenizer to use for tokenization.\n",
    "            max_seq_len (int): The maximum length for the tokenized sequence.\n",
    "    \n",
    "        Returns:\n",
    "            dict: The tokenized output containing input_ids, attention_mask, and offset_mapping.\n",
    "        \"\"\"\n",
    "        return self.config.TOKENIZER(text, return_offsets_mapping=True, truncation=truncation, max_length=max_seq_len)\n",
    "    \n",
    "    def __adjust_start_index(self, start_idx, text):\n",
    "        \"\"\"\n",
    "        Adjust the starting index if the token starts with whitespace.\n",
    "    \n",
    "        Args:\n",
    "            start_idx (int): The start index of the token.\n",
    "            text (str): The full text to check for whitespace.\n",
    "    \n",
    "        Returns:\n",
    "            int: The adjusted start index.\n",
    "        \"\"\"\n",
    "        if text[start_idx].isspace():\n",
    "            return start_idx + 1\n",
    "        return start_idx\n",
    "    \n",
    "    def __align_labels_to_tokens(self, offset_mapping, text, aligned_labels, ltoi):\n",
    "        \"\"\"\n",
    "        Align the labels to the tokenized tokens using offset mapping.\n",
    "    \n",
    "        Args:\n",
    "            offset_mapping (list): The list of token offsets.\n",
    "            text (str): The full original text.\n",
    "            aligned_labels (numpy array): The aligned labels for the original tokens.\n",
    "            label2id (dict): A dictionary mapping label names to IDs.\n",
    "    \n",
    "        Returns:\n",
    "            list: A list of token-level labels.\n",
    "        \"\"\"\n",
    "        tokenized_labels = []\n",
    "    \n",
    "        for start, end in offset_mapping:\n",
    "            # Handle special tokens (like [CLS] token)\n",
    "            if start == 0 and end == 0:\n",
    "                tokenized_labels.append(ltoi[\"O\"])\n",
    "                continue\n",
    "    \n",
    "            start_idx = self.__adjust_start_index(start, text)\n",
    "            tokenized_labels.append(ltoi[aligned_labels[start_idx]])\n",
    "    \n",
    "        return tokenized_labels\n",
    "\n",
    "    def __load_data(self, paths):\n",
    "        df_list = [pd.read_json(path) for path in paths]\n",
    "        df = pd.concat(df_list, ignore_index=True)\n",
    "        print(f\"Loaded {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "        print(\"Preprocessing Data..\")\n",
    "\n",
    "        # positive samples\n",
    "        df[\"postive_samples\"] = df[\"labels\"].apply(lambda row: any((label[:2] == \"B-\" or label[:2] == \"I-\") for label in row))\n",
    "\n",
    "        # negative samples\n",
    "        negative_samples = df[~df[\"postive_samples\"]].sample(frac=self.config.FRAC, random_state=self.config.SEED)\n",
    "\n",
    "        new_df = pd.concat([df[df[\"postive_samples\"]], negative_samples], ignore_index=True)\n",
    "\n",
    "        # drop column used for filtering out positive samples\n",
    "        new_df.drop(columns=[\"postive_samples\"], inplace=True)\n",
    "\n",
    "        df_json = new_df.to_json(orient=\"records\")\n",
    "\n",
    "        data = json.loads(df_json)\n",
    "\n",
    "        return data\n",
    "    \n",
    "    def _preprocess_example(self, example, ltoi, max_seq_len, targets):\n",
    "        \"\"\"\n",
    "        Preprocess an example by tokenizing the text and assigning the corresponding labels.\n",
    "    \n",
    "        Args:\n",
    "            example (dict): The input example containing tokens, labels, and whitespace information.\n",
    "            tokenizer (object): The tokenizer used to convert text into token IDs.\n",
    "            label2id (dict): A dictionary mapping label names to IDs.\n",
    "            max_seq_len (int): The maximum length of the tokenized sequence.\n",
    "    \n",
    "        Returns:\n",
    "            dict: A dictionary containing the tokenized inputs, labels, and sequence length.\n",
    "        \"\"\"\n",
    "        # Step 1: Rebuild text and labels\n",
    "        text, aligned_labels, targets = self.__build_text_and_labels(example, targets)\n",
    "    \n",
    "        # Step 2: Tokenize the text\n",
    "        tokenized_output = self.__tokenize_text(text, max_seq_len)\n",
    "    \n",
    "        # Step 3: Align token-level labels\n",
    "        tokenized_labels = self.__align_labels_to_tokens(tokenized_output[\"offset_mapping\"], text, aligned_labels, ltoi)\n",
    "    \n",
    "        # Step 4: Return the final tokenized output with labels and sequence length\n",
    "        sequence_length = len(tokenized_output[\"input_ids\"])\n",
    "    \n",
    "        return {\n",
    "            **tokenized_output, \n",
    "            \"labels\": tokenized_labels, \n",
    "            \"length\": sequence_length, \n",
    "            \"group\": 1 if sum(targets) > 0 else 0\n",
    "        }\n",
    "\n",
    "    def get_dataset(self):\n",
    "        data = self.__load_data(self.data_paths)\n",
    "        \n",
    "        dataset = Dataset.from_dict({\n",
    "            \"full_text\": [x[\"full_text\"] for x in data],\n",
    "            \"document\": [str(x[\"document\"]) for x in data],\n",
    "            \"tokens\": [x[\"tokens\"] for x in data],\n",
    "            \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "            \"given_labels\": [x[\"labels\"] for x in data],\n",
    "        })\n",
    "\n",
    "        labels = sorted(list(set(chain(*[x[\"labels\"] for x in data]))))\n",
    "        ltoi = {l: i for i, l in enumerate(labels)}\n",
    "        itol = {v: k for k, v in ltoi.items()}\n",
    "        \n",
    "        targets = ['B-EMAIL', 'B-ID_NUM', 'B-NAME_STUDENT', 'B-PHONE_NUM', 'B-STREET_ADDRESS', 'B-URL_PERSONAL', 'B-USERNAME', 'I-ID_NUM', 'I-NAME_STUDENT', 'I-PHONE_NUM', 'I-STREET_ADDRESS', 'I-URL_PERSONAL']\n",
    "        \n",
    "        dataset = dataset.map(self._preprocess_example, fn_kwargs={\n",
    "            \"ltoi\": ltoi, \n",
    "            \"max_seq_len\": self.config.MAX_SEQ_LEN, \n",
    "            \"targets\": targets,\n",
    "        }, num_proc=8)\n",
    "        \n",
    "        # Add fold information for cross-validation\n",
    "        dataset = dataset.add_column(\"fold\", [i % self.config.NUM_FOLDS for i in range(len(dataset))])\n",
    "        dataset = dataset.class_encode_column(\"group\")\n",
    "\n",
    "        return {\n",
    "            \"dataset\": dataset,\n",
    "            \"labels\": labels,\n",
    "            \"ltoi\": ltoi,\n",
    "            \"itol\": itol,\n",
    "            \"targets\": targets,\n",
    "        }\n",
    "\n",
    "    def get_test_dataset(self):\n",
    "        data = json.load(open(\"/kaggle/input/pii-detection-removal-from-educational-data/test.json\"))\n",
    "        \n",
    "        dataset = Dataset.from_dict({\n",
    "            \"full_text\": [x[\"full_text\"] for x in data],\n",
    "            \"document\": [x[\"document\"] for x in data],\n",
    "            \"tokens\": [x[\"tokens\"] for x in data],\n",
    "            \"trailing_whitespace\": [x[\"trailing_whitespace\"] for x in data],\n",
    "        })\n",
    "\n",
    "        def tokenize(data, tokenizer):\n",
    "    \n",
    "            text, token_map = [], []\n",
    "            idx = 0\n",
    "            \n",
    "            for tok, ws in zip(data[\"tokens\"], data[\"trailing_whitespace\"]):\n",
    "                \n",
    "                text.append(tok)\n",
    "                token_map.extend([idx] * len(tok))\n",
    "                \n",
    "                if ws:\n",
    "                    text.append(\" \")\n",
    "                    token_map.append(-1)\n",
    "                    \n",
    "                idx += 1\n",
    "                \n",
    "            tokenized = tokenizer(\"\".join(text), return_offsets_mapping=True, truncation=True, max_length=self.config.MAX_SEQ_LEN)\n",
    "            \n",
    "                \n",
    "            return {**tokenized, \"token_map\": token_map}\n",
    "\n",
    "        dataset = dataset.map(tokenize, fn_kwargs={\"tokenizer\": self.config.TOKENIZER}, num_proc=2)\n",
    "\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feea68f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:59:19.532429Z",
     "iopub.status.busy": "2025-04-14T19:59:19.532184Z",
     "iopub.status.idle": "2025-04-14T19:59:19.547280Z",
     "shell.execute_reply": "2025-04-14T19:59:19.546467Z"
    },
    "papermill": {
     "duration": 0.019502,
     "end_time": "2025-04-14T19:59:19.548597",
     "exception": false,
     "start_time": "2025-04-14T19:59:19.529095",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ModelInference(object):\n",
    "    \"\"\"\n",
    "    A class for performing inference using a trained model for token classification tasks.\n",
    "    \n",
    "    This class handles data loading, model preparation, and inference for token classification,\n",
    "    specifically designed for PII detection tasks.\n",
    "    \n",
    "    Attributes:\n",
    "        config: Configuration object containing model settings and parameters\n",
    "        fold: Integer indicating the current fold for cross-validation\n",
    "        preprocessor: Preprocessor instance for data preparation\n",
    "        tokenizer: Tokenizer instance for text tokenization\n",
    "        dataset: Complete dataset\n",
    "        trainer: Hugging Face Trainer instance\n",
    "        train_dataset: Training dataset split\n",
    "        eval_dataset: Evaluation dataset split\n",
    "        train_losses: List storing training loss values\n",
    "        eval_losses: List storing evaluation loss values\n",
    "        train_f1_scores: List storing training F1 scores\n",
    "        eval_f1_scores: List storing evaluation F1 scores\n",
    "        steps: List storing training steps\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config, fold):\n",
    "        \"\"\"\n",
    "        Initialize the ModelInference object.\n",
    "        \n",
    "        Args:\n",
    "            config: Configuration object containing model settings\n",
    "            fold: Integer indicating which fold to use for validation\n",
    "        \"\"\"\n",
    "        self.config = config\n",
    "        self.preprocessor = Preprocessor(self.config)\n",
    "        self.tokenizer = self.config.TOKENIZER\n",
    "        \n",
    "        self.dataset = None\n",
    "        self.trainer = None\n",
    "        self.train_dataset = None\n",
    "        self.eval_dataset = None\n",
    "        \n",
    "        # Store metrics for plotting\n",
    "        self.train_losses = []\n",
    "        self.eval_losses = []\n",
    "        self.train_f1_scores = []\n",
    "        self.eval_f1_scores = []\n",
    "        self.steps = []\n",
    "\n",
    "        self.fold = fold\n",
    "\n",
    "    def load_data(self):\n",
    "        \"\"\"\n",
    "        Load and split the dataset based on the current fold.\n",
    "        \n",
    "        Loads the complete dataset and splits it into training and validation sets\n",
    "        based on the specified fold number.\n",
    "        \"\"\"\n",
    "        self.dataset = self.preprocessor.get_dataset()\n",
    "        \n",
    "        # Split data based on current fold\n",
    "        current_fold = self.fold\n",
    "        self.train_dataset = self.dataset[\"dataset\"].filter(lambda example: example[\"fold\"] != current_fold)\n",
    "        self.eval_dataset = self.dataset[\"dataset\"].filter(lambda example: example[\"fold\"] == current_fold)\n",
    "        \n",
    "        print(f\"Train dataset size: {len(self.train_dataset)}\")\n",
    "        print(f\"Validation dataset size: {len(self.eval_dataset)}\")\n",
    "\n",
    "    def compute_metrics(self, eval_pred):\n",
    "        \"\"\"\n",
    "        Compute evaluation metrics for the model predictions.\n",
    "        \n",
    "        Args:\n",
    "            eval_pred: Tuple containing predictions and labels\n",
    "            \n",
    "        Returns:\n",
    "            dict: Dictionary containing computed metrics (F1 score)\n",
    "        \"\"\"\n",
    "        predictions, labels = eval_pred\n",
    "        predictions = np.argmax(predictions, axis=2)\n",
    "        \n",
    "        # Remove padding tokens from evaluation\n",
    "        true_predictions = []\n",
    "        true_labels = []\n",
    "        \n",
    "        for prediction, label in zip(predictions, labels):\n",
    "            for i, l in enumerate(label):\n",
    "                if l != -100:  # -100 is the index used for padding\n",
    "                    true_predictions.append(prediction[i])\n",
    "                    true_labels.append(l)\n",
    "        \n",
    "        # Convert numeric labels to string labels for better f1 calculation\n",
    "        true_pred_labels = [self.dataset[\"itol\"][p] for p in true_predictions]\n",
    "        true_gold_labels = [self.dataset[\"itol\"][l] for l in true_labels]\n",
    "        \n",
    "        # Calculate F1 score\n",
    "        f1 = f1_score(true_gold_labels, true_pred_labels, average=\"weighted\")\n",
    "        \n",
    "        return {\n",
    "            \"f1\": f1,\n",
    "        }\n",
    "\n",
    "    def prep_model(self, fold):\n",
    "        \"\"\"\n",
    "        Prepare the model for inference.\n",
    "        \n",
    "        Args:\n",
    "            fold: Integer indicating which fold's model to load\n",
    "        \"\"\"\n",
    "        model = AutoModelForTokenClassification.from_pretrained(f\"/kaggle/input/pii-detection-v1/{self.config.MODEL_NAME.split('/')[1]}_fold_{fold}\")\n",
    "\n",
    "        collator = DataCollatorForTokenClassification(self.tokenizer, pad_to_multiple_of=16)\n",
    "\n",
    "        args = TrainingArguments(\n",
    "            \".\", \n",
    "            per_device_eval_batch_size=1, \n",
    "            report_to=\"none\",\n",
    "        )\n",
    "\n",
    "        print(f\"Predicting on {args.device}\")\n",
    "        \n",
    "        self.trainer = Trainer(\n",
    "            model=model, \n",
    "            args=args, \n",
    "            data_collator=collator, \n",
    "            tokenizer=self.config.TOKENIZER,\n",
    "        )\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"\n",
    "        Run the inference pipeline.\n",
    "        \n",
    "        This method performs the following steps:\n",
    "        1. Loads the test dataset\n",
    "        2. Makes predictions using the model\n",
    "        3. Processes predictions with softmax and thresholding\n",
    "        4. Creates final predictions dataframe\n",
    "        5. Saves predictions to a CSV file\n",
    "        \"\"\"\n",
    "        test_dataset = self.preprocessor.get_test_dataset()\n",
    "        predictions_ = []\n",
    "        self.prep_model(2)\n",
    "        predictions_.append(self.trainer.predict(test_dataset).predictions)\n",
    "\n",
    "        predictions = np.mean(predictions_, axis=0)\n",
    "        pred_softmax = np.exp(predictions) / np.sum(np.exp(predictions), axis = 2).reshape(predictions.shape[0],predictions.shape[1],1)\n",
    "        \n",
    "        preds = predictions.argmax(-1)\n",
    "        preds_without_O = pred_softmax[:,:,:12].argmax(-1)\n",
    "        O_preds = pred_softmax[:,:,12]\n",
    "\n",
    "        cfg = json.load(open(f\"/kaggle/input/pii-detection-v1/{self.config.MODEL_NAME.split('/')[1]}_fold_0/config.json\"))\n",
    "        itol = cfg[\"id2label\"]\n",
    "\n",
    "        threshold = 0.9\n",
    "        preds_final = np.where(O_preds < threshold, preds_without_O, preds)\n",
    "\n",
    "        triplets = []\n",
    "        document, token, label, token_str = [], [], [], []\n",
    "\n",
    "        # Process predictions and create output dataframe\n",
    "        for p, token_map, offsets, tokens, doc in zip(preds_final, test_dataset[\"token_map\"], test_dataset[\"offset_mapping\"], test_dataset[\"tokens\"], test_dataset[\"document\"]):\n",
    "            for token_pred, (start_idx, end_idx) in zip(p, offsets):\n",
    "                label_pred = itol[str(token_pred)]\n",
    "        \n",
    "                if start_idx + end_idx == 0: continue\n",
    "        \n",
    "                if token_map[start_idx] == -1:\n",
    "                    start_idx += 1\n",
    "        \n",
    "                while start_idx < len(token_map) and tokens[token_map[start_idx]].isspace():\n",
    "                    start_idx += 1\n",
    "        \n",
    "                if start_idx >= len(token_map): break\n",
    "        \n",
    "                token_id = token_map[start_idx]\n",
    "        \n",
    "                if label_pred != \"O\" and token_id != -1:\n",
    "                    triplet = (label_pred, token_id, tokens[token_id])\n",
    "        \n",
    "                    if triplet not in triplets:\n",
    "                        document.append(doc)\n",
    "                        token.append(token_id)\n",
    "                        label.append(label_pred)\n",
    "                        token_str.append(tokens[token_id])\n",
    "                        triplets.append(triplet)\n",
    "\n",
    "        df = pd.DataFrame({\n",
    "            \"document\": document,\n",
    "            \"token\": token,\n",
    "            \"label\": label,\n",
    "            \"token_str\": token_str\n",
    "        })\n",
    "        df[\"row_id\"] = list(range(len(df)))\n",
    "        display(df.head(100))\n",
    "\n",
    "        df[[\"row_id\", \"document\", \"token\", \"label\"]].to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4a4cf807",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-14T19:59:19.554015Z",
     "iopub.status.busy": "2025-04-14T19:59:19.553788Z",
     "iopub.status.idle": "2025-04-14T19:59:31.079051Z",
     "shell.execute_reply": "2025-04-14T19:59:31.078331Z"
    },
    "papermill": {
     "duration": 11.529826,
     "end_time": "2025-04-14T19:59:31.080701",
     "exception": false,
     "start_time": "2025-04-14T19:59:19.550875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "==================================================\n",
      "Inference model: microsoft/deberta-v3-base\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "645c5264576a4b648585803d5954d205",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map (num_proc=2):   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting on cuda:0\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>document</th>\n",
       "      <th>token</th>\n",
       "      <th>label</th>\n",
       "      <th>token_str</th>\n",
       "      <th>row_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>482</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>483</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>741</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nathalie</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>7</td>\n",
       "      <td>742</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Sylla</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10</td>\n",
       "      <td>464</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Diego</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>465</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Estrada</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16</td>\n",
       "      <td>4</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gilberto</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>16</td>\n",
       "      <td>5</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Gamboa</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>20</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sindy</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>20</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Samaca</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>20</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Gitam</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>56</td>\n",
       "      <td>12</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Nadine</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Born</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>86</td>\n",
       "      <td>6</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Eladio</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>86</td>\n",
       "      <td>7</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Amaya</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>93</td>\n",
       "      <td>0</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Silvia</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>93</td>\n",
       "      <td>1</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Villalobos</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>104</td>\n",
       "      <td>7</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Dr</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>104</td>\n",
       "      <td>8</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Sakir</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>104</td>\n",
       "      <td>9</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ahmad</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>112</td>\n",
       "      <td>5</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Francisco</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>112</td>\n",
       "      <td>6</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Ferreira</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>123</td>\n",
       "      <td>32</td>\n",
       "      <td>B-NAME_STUDENT</td>\n",
       "      <td>Stefano</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>123</td>\n",
       "      <td>33</td>\n",
       "      <td>I-NAME_STUDENT</td>\n",
       "      <td>Lovato</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    document  token           label   token_str  row_id\n",
       "0          7      9  B-NAME_STUDENT    Nathalie       0\n",
       "1          7     10  I-NAME_STUDENT       Sylla       1\n",
       "2          7    482  B-NAME_STUDENT    Nathalie       2\n",
       "3          7    483  I-NAME_STUDENT       Sylla       3\n",
       "4          7    741  B-NAME_STUDENT    Nathalie       4\n",
       "5          7    742  I-NAME_STUDENT       Sylla       5\n",
       "6         10      0  B-NAME_STUDENT       Diego       6\n",
       "7         10      1  I-NAME_STUDENT     Estrada       7\n",
       "8         10    464  B-NAME_STUDENT       Diego       8\n",
       "9         10    465  I-NAME_STUDENT     Estrada       9\n",
       "10        16      4  B-NAME_STUDENT    Gilberto      10\n",
       "11        16      5  I-NAME_STUDENT      Gamboa      11\n",
       "12        20      5  B-NAME_STUDENT       Sindy      12\n",
       "13        20      6  I-NAME_STUDENT      Samaca      13\n",
       "14        20      8  B-NAME_STUDENT       Gitam      14\n",
       "15        56     12  B-NAME_STUDENT      Nadine      15\n",
       "16        56     13  I-NAME_STUDENT        Born      16\n",
       "17        86      6  B-NAME_STUDENT      Eladio      17\n",
       "18        86      7  I-NAME_STUDENT       Amaya      18\n",
       "19        93      0  B-NAME_STUDENT      Silvia      19\n",
       "20        93      1  I-NAME_STUDENT  Villalobos      20\n",
       "21       104      7  B-NAME_STUDENT          Dr      21\n",
       "22       104      8  B-NAME_STUDENT       Sakir      22\n",
       "23       104      9  I-NAME_STUDENT       Ahmad      23\n",
       "24       112      5  B-NAME_STUDENT   Francisco      24\n",
       "25       112      6  I-NAME_STUDENT    Ferreira      25\n",
       "26       123     32  B-NAME_STUDENT     Stefano      26\n",
       "27       123     33  I-NAME_STUDENT      Lovato      27"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cfg = ConfigCreator(model_name=models[1], lr = lr[0], sl = sl[0], frac = frac[0], bs = bs[0], dataset = dataset[0]).get_config()\n",
    "print(f\"\\n{'='*50}\")\n",
    "print(f\"Inference model: {cfg.MODEL_NAME}\")\n",
    "print(f\"{'='*50}\\n\")\n",
    "\n",
    "\n",
    "model_inference = ModelInference(cfg, 0)\n",
    "model_inference.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c97b1b2",
   "metadata": {
    "papermill": {
     "duration": 0.00302,
     "end_time": "2025-04-14T19:59:31.087362",
     "exception": false,
     "start_time": "2025-04-14T19:59:31.084342",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7500999,
     "sourceId": 66653,
     "sourceType": "competition"
    },
    {
     "sourceId": 233862535,
     "sourceType": "kernelVersion"
    }
   ],
   "dockerImageVersionId": 31012,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 54.524972,
   "end_time": "2025-04-14T19:59:34.676317",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-04-14T19:58:40.151345",
   "version": "2.6.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "31a367b2c62742af86ae864bdf06980d": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "48d24d4c081f45f69304339e8fbd7376": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "645c5264576a4b648585803d5954d205": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_6fa64e6097384aedb68f37cd80e903aa",
        "IPY_MODEL_c7098af526994bcfac91a473c597724e",
        "IPY_MODEL_6d8ce2efd3314a02b69c1f0648f9bef9"
       ],
       "layout": "IPY_MODEL_48d24d4c081f45f69304339e8fbd7376",
       "tabbable": null,
       "tooltip": null
      }
     },
     "6b3f140405e649c2af32278ce13e8d9e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "6d8ce2efd3314a02b69c1f0648f9bef9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_d006942fc7814dcfa1f152f2317c5a7e",
       "placeholder": "​",
       "style": "IPY_MODEL_70c413b11c8143bda62eb0002601eccf",
       "tabbable": null,
       "tooltip": null,
       "value": " 10/10 [00:00&lt;00:00,  8.70 examples/s]"
      }
     },
     "6fa64e6097384aedb68f37cd80e903aa": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_6b3f140405e649c2af32278ce13e8d9e",
       "placeholder": "​",
       "style": "IPY_MODEL_f3d341b1623c4851a964300758bc6ba5",
       "tabbable": null,
       "tooltip": null,
       "value": "Map (num_proc=2): 100%"
      }
     },
     "70c413b11c8143bda62eb0002601eccf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "995eae0030544f9e838f11f695b7f99d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "c7098af526994bcfac91a473c597724e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_31a367b2c62742af86ae864bdf06980d",
       "max": 10,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_995eae0030544f9e838f11f695b7f99d",
       "tabbable": null,
       "tooltip": null,
       "value": 10
      }
     },
     "d006942fc7814dcfa1f152f2317c5a7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "f3d341b1623c4851a964300758bc6ba5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
